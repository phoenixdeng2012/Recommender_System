{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based what items a user rated, a user-user similarity matrix can be build. Each user is represented as a vector, and cosine similarity is used to quantify how similiar two users are. \n",
    "Let's say if we want to recommend movies to Bob, we can then look up similiar users as Bob, pick up 10 most similar user using KNN and recommend items the other 10 similar users like but Bob hasn't seen yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MovieLens import MovieLens\n",
    "from surprise import KNNBasic\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from RecommenderMetrics import RecommenderMetrics\n",
    "from EvaluationData import EvaluationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadMovieLensData():\n",
    "    ml=MovieLens()\n",
    "    data=ml.loadMovieLensLatestSmall()\n",
    "    print('computing movie popularity ranks, later we will use this to measure novelty...')\n",
    "    rankings = ml.getPopularityRanks()\n",
    "    return (ml, data, rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing movie popularity ranks, later we will use this to measure novelty...\n"
     ]
    }
   ],
   "source": [
    "ml, data, rankings = LoadMovieLensData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalData = EvaluationData(data, rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet= evalData.GetLOOCVTrainSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "[1.         0.98       0.88435552 0.95739835 0.88131273 0.963423\n",
      " 0.94722266 0.93977491 0.94050468 0.95418766]\n"
     ]
    }
   ],
   "source": [
    "# calculate the similarity matrix. Using surprise package.\n",
    "\n",
    "sim_options= {'name':'cosine','user_based': True}\n",
    "\n",
    "model=KNNBasic(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simMatrix= model.compute_similarities()\n",
    "\n",
    "print(simMatrix[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftOutTestSet= evalData.GetLOOCVTestSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get topN recommendations\n",
    "\n",
    "topN= defaultdict(list)\n",
    "k=10\n",
    "\n",
    "for uiid in range(trainSet.n_users):\n",
    "    # get top N similar users to this one\n",
    "    similarityRow=simMatrix[uiid]\n",
    "    \n",
    "    similarUsers=[]\n",
    "    for innerID, similarity_score in enumerate(similarityRow):\n",
    "        if innerID != uiid:\n",
    "            similarUsers.append((innerID, similarity_score))\n",
    "    KNeighbors = heapq.nlargest(k, similarUsers, key=lambda x: x[1])\n",
    "    \n",
    "    # get the stuff they rated, and add up ratings for each item, weighted by user similarity\n",
    "    \n",
    "    candidates = defaultdict(float)\n",
    "    for user in KNeighbors:\n",
    "        SimilarityScore=user[1]\n",
    "        for ratings in trainSet.ur[user[0]]:\n",
    "            candidates[ratings[0]] += ratings[1]/5.0*SimilarityScore\n",
    "            \n",
    "    # build a dictionary of movies the subject has already watched\n",
    "    watched={}\n",
    "    for item, rating in trainSet.ur[uiid]:\n",
    "        watched[item]=1\n",
    "        \n",
    "    # Get top-rated items from similar users that our subject hasn't watched yet: top 40 recommendations\n",
    "\n",
    "    loop=0\n",
    "    for item, ratingSum in sorted(candidates.items(),key=itemgetter(1),reverse=True):\n",
    "        if item not in watched:\n",
    "            movie_id=trainSet.to_raw_iid(item)\n",
    "            topN[int(trainSet.to_raw_uid(uiid))].append((int(movie_id), ratingSum))\n",
    "            loop+=1\n",
    "            if loop > 40:\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating topN using hit rate:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR 0.04918032786885246\n"
     ]
    }
   ],
   "source": [
    "print(\"HR\",RecommenderMetrics.HitRate(topN, leftOutTestSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
